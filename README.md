# Cервис поддержки обмена данными (data exchange support service)

## Преамбула

По работе занимаемся организацией межведомственного обмена, когда данные одного ведомства нужно передать в другое.
Такой обмен сопровождается:
- контролем входных данных (в случае, если канал связи недоверенный - проверка на вирусы, вложения, инъекции и т.д.; для всех - проверка формата сообщения, проверка электронной подписи в разных форматах)
- изменением формата данных (как правило, XML одного формата в XML другого формата; иногда json)
- отправка данных
- контролем доставки (проверка того, что на каждое отправленное в ведомство сообщение было подтверждение)
- отслеживанием состояния бизнес-процессов (когда сообщения поступают в рамках одного бизнес-процесса и нужно проверять правильность последовательности)

Некоторые особенности рабочей системы:
- размер сообщений от 10КБ до 10MБ (среднее 500 кб)
- размер сообщений обусловлен наличием бинарных данных (base64)
- нагрузка в пиках до 100 тыс/час
- сообщения имеют уникальные идентификаторы; при генерации нового сообщения, как правило, формируется новый идентификатор в соответствии с новым форматом
- ведомства могут присылать сообщения повторно; система должна вести себя идемпотентно (отправителю нужно вернуть OK, новых сообщений не формируется)
- принцип почты - ведомство получает подтверждение о доставке от Системы, а Система уже отвечает за доставку до другого ведомства
- проверки данных бывают достаточно ресурсоемкими, поэтому основная часть проверок проходит асинхронно; фактом приема в обработку является формирование служебного сообщения-подтверждения, а не HTTP 200/201.   
- есть время удаления бизнес-данных
- есть время удаления мета-данных

## Описание проекта (возможны корректировки)

В проекте разрабатывается система обмена данными. Для простоты считаем что одна внешняя система присылает XML, 
другая принимает JSON.

![context](./docs/architecture/c4-context.drawio.png)

Будет реализовано пять java-сервисов: GateWay, Receiver, BlobStorage, Generator, OutWay, а так же использованы ряд 
готовых контейнеров.

![containers](./docs/architecture/c4-containers.drawio.png)

**Прим**. Применяю два подхода, которые мы сейчас используем в проде:
1. Раздельная обработка обычных данных и бинарных - бинарные данные лежат в отдельном хранилище, в БД лежат только обычные данные и ссылки на блобы. В сообщения при хранении вставляются base64(ссылка_блоб). В качестве ссылок применяем хэш. Блобы подгружаются только когда они реально необходимы. С точки зрения прикладного софта(а также XML/JSON декодеров) ему нет разницы - реальный ли это блоб или ссылка.
2. Для обеспечения асинхронности используем очереди на Redis ZSET. Использование ZSET позволяет защититься от дублей + за счет манипуляций со score, можно управлять порядком обработки сообщений. (паттерн Сага в варианте хореография) 

В проекте хотел бы отработать трассировку этих операций 

## gateway 
SpringCloudGateway reactive - сервис. Принимает данные, от внешней системы по определенном ендпоинту, делает проверу, 
добавляет processId и роутит их на Receiver. 

Фильтры:
- RPM 10/min (RequestRateLimiter gateway filter cluster на redis) 
- CircuitBreaker (resilience4j)
- Кастомный фильтр (добавляет заголовки)
- Кастомный фильтр (проверяет входной xml)

Метрики:
- cpu/ram
- rpm на endpoint
- кол-во ошибок в обработке
- rest pool

### Используемые навыки:
1. 14 - Разбор JMeter и организация нагрузочного тестирования (gateway-service/gateway-jmeter.jmx). 
2. 22 - Реактивное программирование: Reactor
3. 23 - Реактивное программирование: Профилирование приложения на Reactor  (ValidateInputXMLGatewayFilterFactory.apply - onSuccess, onError)
4. 37 - Шаблоны проектирования отказоустойчивого сервиса (Resilience4j CircuitBreaker) (application.yaml)
5. 30 - Сквозное логирование в микросервисах. (opentelemetry) 
6. 31 - Проектирование и архитектура в разрезе микросервисов (API Gateway)

[Описание настроек для gateway](docs/adr/001-gateway-hints.md)
![zipkin-tracing](docs/img/01-gateway-zipkin-tracing.png)


## models
Содержит DTO-модели (jaxb, json) + jmh - тесты
![jaxb-jmh-results](docs/img/02-jmh-jaxb-results.png)
### Используемые навыки:
1. 13 - Разбор библиотеки Java Microbenchmark Harness

## jfr-image
Содержит python-сервис для снятия jfr с работающего контейнера + сборка jre + cmd.

подробности [jfr](docs/adr/003-jfr-docker.md)

### Используемые навыки:
1. 18 - Профилирование java приложений. Thread dump, JFR
2. 11 - JDK tools



## Receiver
java - REST-сервис. (reactor + swagger)

Синхронно:
- извлекает из сообщения идентификатор сообщения, код ведомства (классификатор), тип сообщения(классификатор) (по QName какого-нибудь элемента)
- проверяет возможность использования данного типа сообщения для ведомства
- проверяет по БД не дубликат ли это (далее для трассировки будет использоваться processGUID равный processId, или, если дубликат, будет использоваться существующий processGUID (сообщение может залететь повторно))
- извлекает блобы из сообщения, заменив их ссылками на блоб (хэш от данных MurmurHash) и раздельно сохраняет блобы и сообщение со ссылками в BlobStorage по пути ${processGUID}/имя_файла
- отправляет в ZSET в редисе в виде base64url(processGUID, messageID, messageType) для дальнейшей асинхронной обработки

Метрики: 
- cpu/ram
- кол-во отказов в обработке из-за некорректного типа/неизвестного кода ведомства
- grpc pool
- redis pool
- database pool

Траселог:
- прием сообщений, работа с processId(новое сообщение/существующее), обращение к БД и BlobStorage (интересуют события по processGUID), отправка в redis

## BlobStorage
java - GRPC + openapi (specification first) сервис, отвечающий за хранение бинарных данных (блобы и тела сообщений) по принципу key-value хранилище, где key - ключ вида $processGUID/blob_hash.
Планирую трехуровневую систему хранения:
S3 - как основное (планирую для простоты minio)
Redis - общий кэш с ttl
SoftReference - внутренни кэш

Метрики:
- cpu/ram
- работа GC (интересно сравнить работу с SoftReference и без)

## Generator
java - сервис, отвечающий за генерацию json в зависимости от типа переданного сообщения. Генерирует новый идентификатор сообщения (считаем что формат messageID меняется вместе с форматом сообщения).

(jmh - можно помереть генерацию json freemarker, jackson или gson; с блобами и без)

- извлекает из ZSET сообщение в виде base64url(processGUID, messageID, messageType) 
- по processGUID и messagID извлекает XML по messageID
- по messageType восстанавливает соответствующий jaxb-объект, маппит его в нужный DO, который преобразует в json; для json генерирует новый идентификатор
- json сохраняет в хранилище, в БД сохраняет соответствие messageID и jsonId. Если данные в БД уже были(пришёл повтор) - то ничего нового не генерируем (Идемпотентность !!) 
- отправляет в ZSET сообщение в вида base64url(processGUID, jsonID, receiverDepartmentCode)

Траселог:
- прием сообщений/отправка сообщений через redis, чтение/запись из BlobStorage, генерация

Актуатор: 
- включение - отключение генерации через отключение прослушивания ZSET; хотелось бы реализовать получение сигналов из kafka

## OutWay
java - сервис, отвечающий за отправку данных.

- извлекает из ZSET сообщение в виде base64url(processGUID, jsonID, receiverDepartmentCode)
- вносит в БД данные об отправке
- по шедулеру определяет то, что нужно отправить, определяет url по receiverDepartmentCode, восстанавливает полный json и отправляет данные (select for update skip locked)

Траселог:
- прием запросов на отправку через redis
- отправка данных

Метрики:
- кол-во отправок по url
- скорость отправки данных (rpm)
- кол-во ошибок при отправках по url

Актуатор:
- включение/отключение отправки на данный департамент через kafka

# Дополнения
- есть желание добавить в базовые контейнеры добавить возможность получения результата работы jcmd по снятию jfr для целевого процесса
- для отладки работы предполагается использовать docker-compose/для развертывания облако на yandex-cloud

